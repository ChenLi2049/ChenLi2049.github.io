<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Programming on Chen Li</title><link>https://ChenLi2049.github.io/tags/programming/</link><description>Recent content in Programming on Chen Li</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 29 Sep 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://ChenLi2049.github.io/tags/programming/atom.xml" rel="self" type="application/rss+xml"/><item><title>Safety Issue of Metaverse</title><link>https://ChenLi2049.github.io/posts/20230929-safety-issue-of-metaverse/</link><pubDate>Fri, 29 Sep 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230929-safety-issue-of-metaverse/</guid><description>In this interview about Metaverse, Lex does not mention safety issue, not even once. I understand how exciting he must be to cross the uncanny valley, but this is highly unprofessional and the interview is approximately a commercial.
I don&amp;rsquo;t think I have to stress how absurd this is:
Scaling your head, more in detail. Because they &amp;ldquo;want to capture your facial expressions&amp;rdquo;. Scaling your house (possibly your family and friends).</description></item><item><title>Machine Learning Notes: A Hackers' Guide to Language Models</title><link>https://ChenLi2049.github.io/posts/20230928-machine-learning-notes-a-hackers-guide-to-language-models/</link><pubDate>Thu, 28 Sep 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230928-machine-learning-notes-a-hackers-guide-to-language-models/</guid><description>Jeremy Howard put a video on YouTube about LLMs: A Hackers&amp;rsquo; Guide to Language Models - YouTube, and the GitHub link is lm-hackers. I would watch it again if I were to do the research on LLMs.
The level of detail in this video is amazing. And by &amp;ldquo;the level of detail&amp;rdquo;, I mean
Python code that teaches ChatGPT to run a Python function. Which is powerful, quite handy and embarrassingly simple1.</description></item><item><title>Google Podcasts Shuts Down</title><link>https://ChenLi2049.github.io/posts/20230927-google-podcasts-shuts-down/</link><pubDate>Wed, 27 Sep 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230927-google-podcasts-shuts-down/</guid><description>Another gravestone on Google Graveyard.
Technically it&amp;rsquo;s not shut down, it&amp;rsquo;s gonna be integrated with YouTube Music. So after YouTube Shorts, which is similar to TikTok, YouTube will start promoting music services now. Instead of using that, I&amp;rsquo;m starting to go through open source podcast apps on GitHub.
Since you can also subscribe things on Google Podcasts with RSS, I consider its shut down the splash of Google Reader&amp;rsquo;s death. This sentence from Wikipedia page about Google Reader is ironic:</description></item><item><title>Machine Learning Notes: GraphNeT</title><link>https://ChenLi2049.github.io/posts/20230910-machine-learning-notes-graphnet/</link><pubDate>Sun, 10 Sep 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230910-machine-learning-notes-graphnet/</guid><description>Technically this is only part of the entire blog post. My .ipynb are available at GitHub repository blog-graphnet, see §3.
§1 Graph &amp;amp; Matrix Graphs can be represented by adjacency matrix, which can be normalized into Frobenius normal form, see Matrices and graphs - by Tivadar Danka - The Palindrome.
Often, large part of the matrix is empty, which is called Sparse matrix.
§2 GNN See A Gentle Introduction to Graph Neural Networks - Distill.</description></item><item><title>Machine Learning Notes: Mojonization</title><link>https://ChenLi2049.github.io/posts/20230909-machine-learning-notes-mojonization/</link><pubDate>Sat, 09 Sep 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230909-machine-learning-notes-mojonization/</guid><description>mojonization: n. the migration and translation from Python to Mojo, the superset of Python. (Yeah I made up this word, as far as I know. Cross Mojonization is a totally different thing.)
This article summarizes this process and is my notes / cheat sheet. Note that Mojo is relatively new and some rules might be changing rapidly, thus this article can be outdated easily. So please always check the official documents.</description></item><item><title>Machine Learning Notes: Jupyter Notebook 7, Torch 2.0, Mojo Locally</title><link>https://ChenLi2049.github.io/posts/20230908-machine-learning-notes-jupyter-notebook-7-torch-20-mojo-locally/</link><pubDate>Fri, 08 Sep 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230908-machine-learning-notes-jupyter-notebook-7-torch-20-mojo-locally/</guid><description>It&amp;rsquo;s wild all of these are happening so fast!
On my local computer:
I updated Jupyter Notebook to v7.0.3, and my post Conda 101 is updated. On the server:
CUDA version is now 11.7 and reaches the minimum requirement of torch 2.0. Mojo can be installed locally now, see Mojo 🔥 available for local download! Just imagine the speed! Installing process is gonna be hell, but I&amp;rsquo;m ready to go.</description></item><item><title>Machine Learning Notes: Mojo</title><link>https://ChenLi2049.github.io/posts/20230721-machine-learning-notes-mojo/</link><pubDate>Fri, 21 Jul 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230721-machine-learning-notes-mojo/</guid><description>Mojo🔥 is magic. Check out this interview with the founder of Mojo: Chris Lattner: Future of Programming and AI | Lex Fridman Podcast #381 - YouTube. Integrated with python and using multiple CPU/GPU/TPU is unbelievable.
I think the name is actually kinda cool. Though I&amp;rsquo;m sure when it&amp;rsquo;s released (fingers crossed), someone will fork it and name it Dojo, or Casa, or House.
Starting from 8 Sep 2023, it&amp;rsquo;s available for local download!</description></item><item><title>Machine Learning Notes: fastai</title><link>https://ChenLi2049.github.io/posts/20230706-machine-learning-notes-fastai/</link><pubDate>Thu, 06 Jul 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230706-machine-learning-notes-fastai/</guid><description>Compared with tensorflow, mxnet, paddle or pure numpy (just for the fun of it), torch is probably the easiest Machine Learning package, and to get it even easier, let&amp;rsquo;s take a look at fastai.
By the way, I subscribed GitHub Trending by RSS and the other day I got these two at the same time. Machine Learning in numpy is really cool, but the second one is like, why? &amp;hellip; these two target markets do NOT overlap.</description></item><item><title>Machine Learning Notes: Workflow &amp; Tips</title><link>https://ChenLi2049.github.io/posts/20230701-machine-learning-notes-workflow-tips/</link><pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230701-machine-learning-notes-workflow-tips/</guid><description>Here are my notes from Zero to Mastery Learn PyTorch for Deep Learning. For cheatsheet, see PyTorch Cheatsheet - Zero to Mastery Learn PyTorch for Deep Learning or Create a training/testing loop or PyTorch documentation.
§1 Workflow Most of the time it&amp;rsquo;s necessary to subclass the classes mentioned above, check PyTorch documentation.
§2 Tensor Error See The Three Most Common Errors in PyTorch - Zero to Mastery Learn PyTorch for Deep Learning.</description></item><item><title>Machine Learning Notes: Vision Transformer (ViT)</title><link>https://ChenLi2049.github.io/posts/20230624-machine-learning-notes-vision-transformer/</link><pubDate>Sat, 24 Jun 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230624-machine-learning-notes-vision-transformer/</guid><description>(There are a lot of pictures in this post so it might take a while to load.)
Original paper is [2010.11929] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. Here&amp;rsquo;s some notes from 08. PyTorch Paper Replicating - Zero to Mastery Learn PyTorch for Deep Learning.
The relation between this structure and the equations:
First import packages:
import torch import torch.nn as nn import torch.nn.functional as F from torchinfo import summary §1 Embedding This section is based on Eq.</description></item><item><title>Machine Learning Notes: Transformer</title><link>https://ChenLi2049.github.io/posts/20230615-machine-learning-notes-transformer/</link><pubDate>Thu, 15 Jun 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230615-machine-learning-notes-transformer/</guid><description>This is my notes from [1706.03762] Attention Is All You Need and The Annotated Transformer and The Illustrated Transformer. This is an outline, I&amp;rsquo;m trying to keep it as simple as possible. You can import these layers and blocks from torch.nn, see Transformer Layers — PyTorch 2.0 documentation. And I will focus more on structure rather than code itself, because building this model on torch.nn is much simpler, see Language Modeling with nn.</description></item><item><title>Machine Learning Notes: torch.nn</title><link>https://ChenLi2049.github.io/posts/20230614-machine-learning-notes-torch-nn/</link><pubDate>Wed, 14 Jun 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230614-machine-learning-notes-torch-nn/</guid><description>This is a quick introduction to torch or how to build a neural network without writing the source code. For the purpose of each layer, see torch.nn and Dive into Deep Learning. Basically, after CNN, parts of the picture is highlighted and the number of channels (RGB $\rightarrow$ many more) can be different (see CNN Explainer).
In the following code, first import the required packages:
import torch import torch.nn as nn import torch.</description></item><item><title>Contamination of LLM</title><link>https://ChenLi2049.github.io/posts/20230613-contamination-of-llm/</link><pubDate>Tue, 13 Jun 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230613-contamination-of-llm/</guid><description>This is the dark side of the Force.
In one of my previous posts, I talked about Ted Chiang&amp;rsquo;s idea on LLMs. At that time his idea only seems plausible, but now that more papers are published, I want to talk about how LLMs are contaminating the source material.
Training LLM with LLM-produced material will produce terrible results.1 This is $\text{Ted Chiang&amp;rsquo;s idea}^n$.
And the contamination can be divided into two parts in general:</description></item><item><title>immersive-translate</title><link>https://ChenLi2049.github.io/posts/20230602-immersive-translate/</link><pubDate>Fri, 02 Jun 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230602-immersive-translate/</guid><description>immersive-translate is a great translating extension, which has a nice format, can open .epub file and translate .epub file directly.
There&amp;rsquo;s a bug, when translating Feedly, the translated content in the side bar would convert with the original content. According to 高级自定义配置, I used:
[ { &amp;#34;matches&amp;#34;: &amp;#34;feedly.com&amp;#34;, &amp;#34;excludeSelectors&amp;#34;: [ &amp;#34;nav&amp;#34;, &amp;#34;footer&amp;#34; ] } ] Learning a little html is really useful.
For the translation box, I used purple quotation-style.</description></item><item><title>LaTeX Style</title><link>https://ChenLi2049.github.io/posts/20230521-latex-style/</link><pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230521-latex-style/</guid><description>If you don&amp;rsquo;t know what it is, I recommend you should just play with it and don&amp;rsquo;t care about the style.
But I&amp;rsquo;d like to say TinyTeX (~500 MB) or Overleaf (0 MB) are better choices than TeX Live (~5 GB). I normally write in Markdown first, and then use Overleaf. If you&amp;rsquo;re using JupyterLab, jupyterlab-latex is basically the local version of Overleaf.
§1 General About the name: $\LaTeX$ ($\LaTeX$) is great, LaTeX or latex is acceptable, lAtEx is brutal.</description></item><item><title>Markdown Style</title><link>https://ChenLi2049.github.io/posts/20230521-markdown-style/</link><pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230521-markdown-style/</guid><description>If you don&amp;rsquo;t know what it is, I recommend you should just play with it and don&amp;rsquo;t care about the style.
Obsidian is the text editor that I&amp;rsquo;m using. I like workspaces and double link feature.
§1 General Markdown Guide is good as a quick introduction.
The thing about Markdown style is that every text editor has its own accent. I suggest using the universal ones, not the ones that a certain text editor created.</description></item><item><title>Python Style</title><link>https://ChenLi2049.github.io/posts/20230521-python-style/</link><pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230521-python-style/</guid><description>If you don&amp;rsquo;t know what it is, I recommend you should just play with it and don&amp;rsquo;t care about the style.
But I&amp;rsquo;d like to say Anaconda is a better choice than just Python itself. You can manage different packages in different environments with Anaconda.
This article is about what I find interesting in PEP 8 – Style Guide for Python Code1, PEP 257 – Docstring Conventions, Style guide — numpydoc v1.</description></item><item><title>New Repository: PEP-8-ZH</title><link>https://ChenLi2049.github.io/posts/20230520-new-repository-pep-8-zh/</link><pubDate>Sat, 20 May 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230520-new-repository-pep-8-zh/</guid><description>I created a repository called PEP-8-ZH. Basically, I translated PEP 8 with the help of ChatGPT, and with a little modification myself. The prompt that I use is:
将下文翻译为中文 And I did not translate the comments, because you should try to write comments in English.
If you want to learn about Python style, I recommend Google Style Guides (中文版见 Google 开源项目风格指南) as the guide. Which is more up to date. I&amp;rsquo;ll write about Python style soon.</description></item><item><title>List of a Folder</title><link>https://ChenLi2049.github.io/posts/20230423-list-of-a-folder/</link><pubDate>Sun, 23 Apr 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230423-list-of-a-folder/</guid><description>§1 path In Windows, to get the list of all the files in a folder:
Create a .txt file.
Open it with notepad. Copy and paste the following commands:
@echo off dir %1 /s/b &amp;gt; %~n1.txt Or, if you don&amp;rsquo;t want the list of what&amp;rsquo;s in the subdirectory:
@echo off dir %1 /b &amp;gt; %~n1.txt Rename it getList.bat (&amp;ldquo;getList&amp;rdquo; could be anything.)
Drag the target folder to this .bat file.</description></item><item><title>New Repository: DrSlidelove</title><link>https://ChenLi2049.github.io/posts/20230423-new-repository-slidy/</link><pubDate>Sun, 23 Apr 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230423-new-repository-slidy/</guid><description>Update 20230617: I&amp;rsquo;m so sorry that there&amp;rsquo;s already a Slidy. When I used that name for this repository, there&amp;rsquo;s no such a repository named Slidy and I thought it would be ok. To avoid any confusion, the name is changed from Slidy to DrSlidelove. Again, my apologies.
I just created a new repository for slide, which is called Slidy. Well, technically I didn&amp;rsquo;t create it, I just moved stuff around.</description></item><item><title>Conda 101</title><link>https://ChenLi2049.github.io/posts/20230327-conda-101/</link><pubDate>Mon, 27 Mar 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230327-conda-101/</guid><description>This article is a quick guidance to use Anaconda &amp;amp; Miniconda on Windows. I wrote it so that I can check the command myself. Sorry about other platforms such as Linux, WSL on Windows or MacOS, but the §2 should be useful too.
§1 Anaconda Go the the official website Anaconda and download the default exe file. Open and install it. Get familiar with Jupyter Notebook. Feel free to check out some other articles and mess around, knowing that you can always delete the old environment and start from scratch, you&amp;rsquo;ll be fine.</description></item><item><title>Robin</title><link>https://ChenLi2049.github.io/posts/20230321-robin/</link><pubDate>Tue, 21 Mar 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230321-robin/</guid><description>Besides writing code, having ChatGPT pretend to be Robin from How I Met Your Mother and engaging in a conversation with her is so funny. She is constantly making things up and I am trying my best to make the story work. And when it does, it&amp;rsquo;s amazing!
It&amp;rsquo;s even more fun to ask ChatGPT to be Jamie Lannister, since there is (part of) a whole novel and countless online discussions.</description></item><item><title>RSS: Why and How?</title><link>https://ChenLi2049.github.io/posts/20230304-rss-why-and-how/</link><pubDate>Sat, 04 Mar 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230304-rss-why-and-how/</guid><description>RSS, personal website and the word &amp;ldquo;neat&amp;rdquo; shared a lot in common, one of which is that they died out at the beginning of this century but have become more useful ever since.
§1 Why? The whole goal of RSS is to keep it simple. I don&amp;rsquo;t want to check a lot of websites over and over again. Something should be read and then forgotten, unless it&amp;rsquo;s important, in which case I will mark it down.</description></item><item><title>寒武纪 MLU370-X4 安装在本地服务器的 ubuntu 上</title><link>https://ChenLi2049.github.io/posts/20230304-gpu-dock/</link><pubDate>Sat, 04 Mar 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230304-gpu-dock/</guid><description>还未经测试!
显卡：寒武纪 MLU370-X4。
显卡坞的解决方式恐怕不行，因为如果重新更换设备需要重新从 ubuntu 开始装起，不如在另一台机器上构建一个本地服务器。除此之外的问题还有：笔记本自带的核显会打架吗？硬盘容量不够了。:(
视频介绍（除3.几乎完全是这个知乎专栏的内容）：
寒武纪 MLU370 加速卡简介及安装 寒武纪基础软件平台安装 MLU370 开发实战 文档（在熟悉视频介绍之后再查看）：
文档中心 MLU370-X4 智能加速卡产品手册 1.0.0 文档 我设想的本地服务器的构建流程：
安装 ubuntu，版本号见视频介绍：16.04或18.04? 按照视频介绍安装 torch.mlu 组件等等（和 Dive into Deep Learning1 这本书不同的地方在于，寒武纪在使用 pytorch 时导入 torch 和 torch.mlu 即可，不需安装 torchvision 即 pytorch 的 GPU 版本，此处 mlu 和 gpu 是两个相对的概念，指调用的底层架构不同） 安装 JupyterNotebook。 尝试寒武纪开发的工具 MagicMind 和 YOLOv5。见 Cambricon(gitee.com)。 另一本很推荐的书是《智能计算系统》&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>Hello World</title><link>https://ChenLi2049.github.io/posts/20230303-hello-world/</link><pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230303-hello-world/</guid><description>Hello World!</description></item></channel></rss>