<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Chen Li</title><description>Chen Li's personal blog</description><link>https://ChenLi2049.github.io</link><language>en</language><copyright>Copyright 2023, Calvin Tran</copyright><lastBuildDate>Thu, 07 Sep 2023 00:00:00 +0000</lastBuildDate><generator>Hugo - gohugo.io</generator><docs>http://cyber.harvard.edu/rss/rss.html</docs><atom:link href="https://ChenLi2049.github.io/atom.xml" rel="self" type="application/atom+xml"/><item><title>XRISM &amp; SLIM</title><link>https://ChenLi2049.github.io/posts/20230907-xrism-slim/</link><description>&lt;p>X-Ray Imaging and Spectroscopy Mission (XRISM) is an X-ray space telescope. On the same rocket there&amp;rsquo;s also Smart Lander for Investigating Moon (SLIM), a moon landing project.&lt;/p>
&lt;p>XRISM&amp;rsquo;s predecessor Hitomi was launched on 17 February 2016 and contact was lost on 26 March 2016, due to malfunction of the attitude control system. After which, a lot changed. For example, &lt;a href="https://arxiv.org/abs/2106.01611">this article&lt;/a> explained the team management of XRISM, which is like an analogue of government system.&lt;/p>
&lt;p>And here&amp;rsquo;s a &lt;a href="https://github.com/ChenLi2049/ChenLi2049/blob/main/presentations/20220815_G1Presentation_XRISM.pptx">presentation&lt;/a> from my group project last summer, which is a quick introduction to XRISM. I do (not) miss using Microsoft PPT, those were simpler times.&lt;/p>
&lt;p>It&amp;rsquo;s a bit weird that writing about something makes you care about it more. I mean, I did not participate in the manufacturing process or anything. I guess this is also one of the meanings of this blog.&lt;/p>
&lt;p>XRISM, hang in there! Wow this is a pun. So, um &amp;hellip; SLIM, don&amp;rsquo;t?&lt;/p></description><author>Chen Li</author><guid>https://ChenLi2049.github.io/posts/20230907-xrism-slim/</guid><pubDate>Thu, 07 Sep 2023 00:00:00 +0000</pubDate></item><item><title>New Paper on arXiv &amp; New Repository: ISeeCube</title><link>https://ChenLi2049.github.io/posts/20230828-new-paper-on-arxiv-new-repository-iseecube/</link><description>&lt;p>The arXiv link is &lt;a href="https://arxiv.org/abs/2308.13285v1">2308.13285v1&lt;/a> and the Repository is &lt;a href="https://github.com/ChenLi2049/ISeeCube">ISeeCube&lt;/a>. Here&amp;rsquo;s what I learned and what to do next.&lt;/p>
&lt;h2 id="what-i-learned">What I learned&lt;/h2>
&lt;ul>
&lt;li>Test the code by &lt;code>print()&lt;/code> everything.&lt;/li>
&lt;li>Input and output are the most important thing. Test these while reading the code.&lt;/li>
&lt;li>Read official package documentation for examples.&lt;/li>
&lt;li>ChatGPT is good at analyzing error report and giving examples, but not so much at writing code, especially when there&amp;rsquo;s already a lot of code.&lt;/li>
&lt;/ul>
&lt;h2 id="to-do">To Do&lt;/h2>
&lt;ul>
&lt;li>Train the model with VMF Loss. So that the distribution of azimuthal and zenithal error is in better shape.&lt;/li>
&lt;li>Try different kinds of Embedding. In NLP, a random Embedding &lt;code>nn.Embedding&lt;/code> will get nice results too. Because the structure is big enough.&lt;/li>
&lt;li>Learn the relationship between Graph and &lt;a href="https://en.wikipedia.org/wiki/Sparse_matrix">Sparse Matrix&lt;/a>, see &lt;a href="https://thepalindrome.org/p/matrices-and-graphs">&lt;em>Matrices and graphs&lt;/em> - by Tivadar Danka - The Palindrome&lt;/a>. Learn GNN and &lt;a href="https://github.com/graphnet-team/graphnet">&lt;code>GraphNeT&lt;/code>&lt;/a>.&lt;/li>
&lt;li>Learn &lt;a href="https://arxiv.org/abs/1911.03584">why Transformers are CNNs&lt;/a>, &lt;a href="https://towardsdatascience.com/transformers-are-graph-neural-networks-bca9f75412aa">GNNs&lt;/a>, &lt;a href="https://arxiv.org/abs/2006.16236">RNNs&lt;/a>.&lt;/li>
&lt;li>Clean the dataset. Why there are events with pulses nearly $11000$?&lt;/li>
&lt;li>model $\rightarrow$ simulated data $\rightarrow$ reconstruction, and then, real data $\rightarrow$ reconstruction. This workflow probably can be improved by using self-supervised learning directly on real data and then fine-tuning it on simulated data with labels. So that the model is closer to real data than simulated data. This is just an idea, which probably can be tested on the public dataset.&lt;/li>
&lt;/ul></description><author>Chen Li</author><guid>https://ChenLi2049.github.io/posts/20230828-new-paper-on-arxiv-new-repository-iseecube/</guid><pubDate>Mon, 28 Aug 2023 00:00:00 +0000</pubDate></item><item><title>Gravity Spy 2.0</title><link>https://ChenLi2049.github.io/posts/20230810-gravity-spy-2.0/</link><description>&lt;p>You can classify some patterns on &lt;a href="https://www.zooniverse.org/projects/zooniverse/gravity-spy">Gravity Spy&lt;/a> and it&amp;rsquo;s fun. Their GitHub repo is &lt;a href="https://github.com/haorenzhi/gravityspy-plus/tree/main">gravityspy-plus&lt;/a>, and their Wiki is &lt;a href="https://gswiki.ischool.syr.edu/">Gravity Spy 2.0 Wiki&lt;/a>. The Kaggle dataset is &lt;a href="https://www.kaggle.com/datasets/tentotheminus9/gravity-spy-gravitational-waves">Gravity Spy (Gravitational waves)&lt;/a>. Not to be confused with &lt;a href="https://www.kaggle.com/competitions/g2net-gravitational-wave-detection">G2Net&lt;/a>, the format of the data is quite different.&lt;/p>
&lt;p>I took a look of those patterns and I got the idea that we can use Transfer Learning from ordinary Machine Learning models for Computer Vision, because the format is RGB image and it&amp;rsquo;s a classic classification job. Then I look it up on arXiv, there are some papers on this subject. The Fig. 10 of &lt;a href="https://arxiv.org/abs/2303.13917">[2303.13917] &lt;em>Convolutional Neural Networks for the classification of glitches in gravitational-wave data streams&lt;/em>&lt;/a> is crazy, I have never seen so many &amp;ldquo;1&amp;quot;s in the diagonal line of a Confusion Matrix.&lt;/p></description><author>Chen Li</author><guid>https://ChenLi2049.github.io/posts/20230810-gravity-spy-2.0/</guid><pubDate>Thu, 10 Aug 2023 00:00:00 +0000</pubDate></item></channel></rss>