<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Chen Li</title><description>Chen Li's personal blog</description><link>https://ChenLi2049.github.io</link><language>en</language><copyright>Copyright 2023, Calvin Tran</copyright><lastBuildDate>Fri, 29 Sep 2023 00:00:00 +0000</lastBuildDate><generator>Hugo - gohugo.io</generator><docs>http://cyber.harvard.edu/rss/rss.html</docs><atom:link href="https://ChenLi2049.github.io/atom.xml" rel="self" type="application/atom+xml"/><item><title>Safety Issue of Metaverse</title><link>https://ChenLi2049.github.io/posts/20230929-safety-issue-of-metaverse/</link><description>&lt;p>In &lt;a href="https://www.youtube.com/watch?v=MVYrJJNdrEg">this interview about Metaverse&lt;/a>, Lex does not mention safety issue, not even once. I understand how exciting he must be to cross the uncanny valley, but this is highly unprofessional and the interview is approximately a commercial.&lt;/p>
&lt;p>I don&amp;rsquo;t think I have to stress how absurd this is:&lt;/p>
&lt;ul>
&lt;li>Scaling your head, more in detail. Because they &amp;ldquo;want to capture your facial expressions&amp;rdquo;.&lt;/li>
&lt;li>Scaling your house (possibly your family and friends).&lt;/li>
&lt;/ul>
&lt;p>Potentially, anybody can use your avatar to say stuff. And with the help of voice imitation, it will even sound like you. Deepfake still requires the target&amp;rsquo;s pictures or videos for generation, but now you, the target, are giving these information away. I&amp;rsquo;m not saying the company will do it. &lt;em>Leakage is all you need&lt;/em>.&lt;/p>
&lt;p>Privacy, copyright and labeling slavery have always been major ethical problems for Machine Learning. On the contrary, &lt;a href="https://chenli2049.github.io/posts/20230810-gravity-spy-2.0/">classifying patterns of Gravitational Waves&lt;/a> or &lt;a href="https://chenli2049.github.io/posts/20230828-new-paper-on-arxiv-new-repository-iseecube/">reconstructing neutrino events&lt;/a> don&amp;rsquo;t have these ethical problems. Because there are less actual factors involved. And, even if Neural Networks went crazy in the process, nobody would get hurt. One of the examples of its potential craziness is that detection of a disease is related to how old the picture is, see &lt;a href="https://www.youtube.com/watch?v=EUrOxh_0leE">&lt;em>AI does not exist but it will ruin everything anyway&lt;/em> - YouTube&lt;/a>.&lt;/p>
&lt;p>I read about this meme somewhere:&lt;/p>
&lt;blockquote>
&lt;ul>
&lt;li>Me: My dad says you steal users&amp;rsquo; personal information.&lt;/li>
&lt;li>Mark Zuckerberg: He&amp;rsquo;s not your dad.&lt;/li>
&lt;/ul>
&lt;/blockquote></description><author>Chen Li</author><guid>https://ChenLi2049.github.io/posts/20230929-safety-issue-of-metaverse/</guid><pubDate>Fri, 29 Sep 2023 00:00:00 +0000</pubDate></item><item><title>Machine Learning Notes: A Hackers' Guide to Language Models</title><link>https://ChenLi2049.github.io/posts/20230928-machine-learning-notes-a-hackers-guide-to-language-models/</link><description>&lt;p>Jeremy Howard put a video on YouTube about LLMs: &lt;a href="https://www.youtube.com/watch?v=jkrNMKz9pWU">A Hackers&amp;rsquo; Guide to Language Models - YouTube&lt;/a>, and the GitHub link is &lt;a href="https://github.com/fastai/lm-hackers/tree/main">lm-hackers&lt;/a>. I would watch it again if I were to do the research on LLMs.&lt;/p>
&lt;p>The level of detail in this video is amazing. And by &amp;ldquo;the level of detail&amp;rdquo;, I mean&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Python code that teaches ChatGPT to run a Python function. Which is powerful, quite handy and embarrassingly simple&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Links to GitHub repositories, websites, etc. They are often the most useful, because they are sources you will go to &lt;strong>when coding&lt;/strong>, or from these sources you can expand to other sources. Thus they are really helpful if you want to actually do the work instead of having a vague understanding.&lt;/p>
&lt;p>When coding, referring to certain links is a habit that may take some time to grow. I used to have the impression that coding is constantly hitting the keyboard, but what really happened to me is that I spend 70% of time searching and reading other people&amp;rsquo;s code (referring to certain links), 20% writing and testing, 10% debugging. And by showing these links, he reduces the time of searching and reading for the viewers.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>In a sense, they are more close to experience than knowledge. I&amp;rsquo;ll try to do the same thing, try to.&lt;/p>
&lt;p>By the way, it&amp;rsquo;s astonishing to see how Machine Learning community (GitHub repositories, papers, packages, pre-trained models, fine-tuned models, websites, services) can flourish on one task. The variety, both the good and the bad, is beautiful.&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>I love &amp;ldquo;embarrassingly simple&amp;rdquo;. The phrase &amp;ldquo;embarrassingly simple&amp;rdquo; is often used to describe a trend in Machine Learning that, classical heuristic systems is replaced by end-to-end learning systems. Because the world is more complicated than what you can program, that&amp;rsquo;s why we use Machine Learning in the first place. See &lt;a href="https://www.youtube.com/watch?v=rd3R_G6_UfY">Full Self-Driving is HARD! Analyzing Elon Musk re: Tesla Autopilot on Lex Fridman&amp;rsquo;s Podcast - YouTube&lt;/a> where he talked about Tesla 11.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description><author>Chen Li</author><guid>https://ChenLi2049.github.io/posts/20230928-machine-learning-notes-a-hackers-guide-to-language-models/</guid><pubDate>Thu, 28 Sep 2023 00:00:00 +0000</pubDate></item><item><title>Google Podcasts shuts down</title><link>https://ChenLi2049.github.io/posts/20230927-google-podcasts-shuts-down/</link><description>&lt;p>Another gravestone on &lt;a href="https://killedbygoogle.com/">Google Graveyard&lt;/a>.&lt;/p>
&lt;p>Technically it&amp;rsquo;s not shut down, it&amp;rsquo;s gonna be integrated with YouTube Music. So after YouTube Shorts, which is similar to TikTok, YouTube will start promoting music services now. Instead of using that, I&amp;rsquo;m starting to go through open source podcast apps on GitHub.&lt;/p>
&lt;p>Since you can also subscribe things on Google Podcasts with RSS, I consider its shut down the splash of Google Reader&amp;rsquo;s death. This sentence from &lt;a href="https://en.wikipedia.org/wiki/Google_Reader">Wikipedia page about Google Reader&lt;/a> is ironic:&lt;/p>
&lt;blockquote>
&lt;p>In January 2007 Google added video content from YouTube and Google Video to Reader.&lt;/p>
&lt;/blockquote>
&lt;p>Why does every app wants to combine everything in the world? WeiXin did that and it takes about 1 TB of storage in your phone.&lt;/p>
&lt;p>I really hope &amp;ldquo;Shuts Down&amp;rdquo; will not become a series in my posts. That would be sad.&lt;/p></description><author>Chen Li</author><guid>https://ChenLi2049.github.io/posts/20230927-google-podcasts-shuts-down/</guid><pubDate>Wed, 27 Sep 2023 00:00:00 +0000</pubDate></item></channel></rss>