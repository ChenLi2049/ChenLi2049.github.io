<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Chen Li</title><description>Chen Li's personal blog</description><link>https://ChenLi2049.github.io</link><language>en</language><copyright>Copyright 2023, Calvin Tran</copyright><lastBuildDate>Fri, 08 Sep 2023 00:00:00 +0000</lastBuildDate><generator>Hugo - gohugo.io</generator><docs>http://cyber.harvard.edu/rss/rss.html</docs><atom:link href="https://ChenLi2049.github.io/atom.xml" rel="self" type="application/atom+xml"/><item><title>Machine Learning Notes: Jupyter Notebook 7, Torch 2.0, Mojo Locally</title><link>https://ChenLi2049.github.io/posts/20230908-machine-learning-notes-jupyter-notebook-7-torch-20-mojo-locally/</link><description>&lt;p>It&amp;rsquo;s wild all of these are happening so fast!&lt;/p>
&lt;p>On my local computer:&lt;/p>
&lt;ul>
&lt;li>I updated Jupyter Notebook to v7.0.3, and my post &lt;a href="https://chenli2049.github.io/posts/20230327-conda-101/">&lt;em>Conda 101&lt;/em>&lt;/a> is updated.&lt;/li>
&lt;/ul>
&lt;p>On the server:&lt;/p>
&lt;ul>
&lt;li>CUDA version is now &lt;code>11.7&lt;/code> and reaches the minimum requirement of &lt;code>torch 2.0&lt;/code>.&lt;/li>
&lt;li>&lt;code>Mojo&lt;/code> can be installed locally now, see &lt;a href="https://github.com/modularml/mojo/discussions/568">Mojo ðŸ”¥Â available for local download!&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Just imagine the speed! Installing process is gonna be hell, but I&amp;rsquo;m ready to go.&lt;/p></description><author>Chen Li</author><guid>https://ChenLi2049.github.io/posts/20230908-machine-learning-notes-jupyter-notebook-7-torch-20-mojo-locally/</guid><pubDate>Fri, 08 Sep 2023 00:00:00 +0000</pubDate></item><item><title>XRISM &amp; SLIM</title><link>https://ChenLi2049.github.io/posts/20230907-xrism-slim/</link><description>&lt;p>X-Ray Imaging and Spectroscopy Mission (XRISM) is an X-ray space telescope. On the same rocket there&amp;rsquo;s also Smart Lander for Investigating MoonÂ (SLIM), a moon landing project.&lt;/p>
&lt;p>XRISM&amp;rsquo;s predecessor Hitomi was launched on 17 February 2016 and contact was lost on 26 March 2016, due to malfunction of theÂ attitude controlÂ system. After which, a lot changed. For example, &lt;a href="https://arxiv.org/abs/2106.01611">this article&lt;/a> explained the team management of XRISM, which is like an analogue of government system.&lt;/p>
&lt;p>And here&amp;rsquo;s a &lt;a href="https://github.com/ChenLi2049/ChenLi2049/blob/main/presentations/20220815_G1Presentation_XRISM.pptx">presentation&lt;/a> from my group project last summer, which is a quick introduction to XRISM. I do (not) miss using Microsoft PPT, those were simpler times.&lt;/p>
&lt;p>It&amp;rsquo;s a bit weird that writing about something makes you care about it more. I mean, I did not participate in the manufacturing process or anything. I guess this is also one of the meanings of this blog.&lt;/p>
&lt;p>XRISM, hang in there! Wow this is a pun. So, um &amp;hellip; SLIM, don&amp;rsquo;t?&lt;/p></description><author>Chen Li</author><guid>https://ChenLi2049.github.io/posts/20230907-xrism-slim/</guid><pubDate>Thu, 07 Sep 2023 00:00:00 +0000</pubDate></item><item><title>New Paper on arXiv &amp; New Repository: ISeeCube</title><link>https://ChenLi2049.github.io/posts/20230828-new-paper-on-arxiv-new-repository-iseecube/</link><description>&lt;p>The arXiv link is &lt;a href="https://arxiv.org/abs/2308.13285v1">2308.13285v1&lt;/a> and the Repository is &lt;a href="https://github.com/ChenLi2049/ISeeCube">ISeeCube&lt;/a>. Here&amp;rsquo;s what I learned and what to do next.&lt;/p>
&lt;h2 id="what-i-learned">What I Learned&lt;/h2>
&lt;ul>
&lt;li>Test the code by &lt;code>print()&lt;/code> everything.&lt;/li>
&lt;li>Input and output are the most important thing. Test these while reading the code.&lt;/li>
&lt;li>Read official package documentation for examples.&lt;/li>
&lt;li>ChatGPT is good at analyzing error report and giving examples, but not so much at writing code, especially when there&amp;rsquo;s already a lot of code.&lt;/li>
&lt;/ul>
&lt;h2 id="to-do">To Do&lt;/h2>
&lt;ul>
&lt;li>Train the model with VMF Loss. So that the distribution of azimuthal and zenithal error is in better shape.&lt;/li>
&lt;li>Try different kinds of Embedding. In NLP, a random Embedding &lt;code>nn.Embedding&lt;/code> will get nice results too. Because the structure is big enough.&lt;/li>
&lt;li>Learn the relationship between Graph and &lt;a href="https://en.wikipedia.org/wiki/Sparse_matrix">Sparse Matrix&lt;/a>, see &lt;a href="https://thepalindrome.org/p/matrices-and-graphs">&lt;em>Matrices and graphs&lt;/em> - by Tivadar Danka - The Palindrome&lt;/a>. Learn GNN and &lt;a href="https://github.com/graphnet-team/graphnet">&lt;code>GraphNeT&lt;/code>&lt;/a>.&lt;/li>
&lt;li>Learn &lt;a href="https://arxiv.org/abs/1911.03584">why Transformers are CNNs&lt;/a>, &lt;a href="https://towardsdatascience.com/transformers-are-graph-neural-networks-bca9f75412aa">GNNs&lt;/a>, &lt;a href="https://arxiv.org/abs/2006.16236">RNNs&lt;/a>.&lt;/li>
&lt;li>Clean the dataset. Why there are events with pulses nearly $11000$?&lt;/li>
&lt;li>model $\rightarrow$ simulated data $\rightarrow$ reconstruction, and then, real data $\rightarrow$ reconstruction. This workflow probably can be improved by using self-supervised learning directly on real data and then fine-tuning it on simulated data with labels. So that the model is closer to real data than simulated data. This is just an idea, which probably can be tested on the public dataset.&lt;/li>
&lt;/ul></description><author>Chen Li</author><guid>https://ChenLi2049.github.io/posts/20230828-new-paper-on-arxiv-new-repository-iseecube/</guid><pubDate>Mon, 28 Aug 2023 00:00:00 +0000</pubDate></item></channel></rss>