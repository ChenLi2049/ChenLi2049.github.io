<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Liste - https://ChenLi2049.github.io"><title>Machine Learning Notes: GraphNeT | Chen Li</title><meta name=description content="Chen Li's personal blog"><meta property="og:title" content="Machine Learning Notes: GraphNeT"><meta property="og:description" content="Technically this is only part of the entire blog post. My .ipynb are available at GitHub repository blog-graphnet, see §3.
§1 Graph & Matrix Graphs can be represented by adjacency matrix, which can be normalized into Frobenius normal form, see Matrices and graphs - by Tivadar Danka - The Palindrome.
Often, large part of the matrix is empty, which is called Sparse matrix.
§2 GNN See A Gentle Introduction to Graph Neural Networks - Distill."><meta property="og:type" content="article"><meta property="og:url" content="https://ChenLi2049.github.io/posts/20230910-machine-learning-notes-graphnet/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-09-10T00:00:00+00:00"><meta property="article:modified_time" content="2023-09-10T00:00:00+00:00"><meta itemprop=name content="Machine Learning Notes: GraphNeT"><meta itemprop=description content="Technically this is only part of the entire blog post. My .ipynb are available at GitHub repository blog-graphnet, see §3.
§1 Graph & Matrix Graphs can be represented by adjacency matrix, which can be normalized into Frobenius normal form, see Matrices and graphs - by Tivadar Danka - The Palindrome.
Often, large part of the matrix is empty, which is called Sparse matrix.
§2 GNN See A Gentle Introduction to Graph Neural Networks - Distill."><meta itemprop=datePublished content="2023-09-10T00:00:00+00:00"><meta itemprop=dateModified content="2023-09-10T00:00:00+00:00"><meta itemprop=wordCount content="636"><meta itemprop=keywords content="Programming,"><link rel=canonical href=https://ChenLi2049.github.io/posts/20230910-machine-learning-notes-graphnet/><link rel=icon href=https://ChenLi2049.github.io/assets/favicon.ico><link rel=dns-prefetch href=https://www.google-analytics.com><link href=https://www.google-analytics.com rel=preconnect crossorigin><link rel=alternate type=application/atom+xml title="Chen Li" href=https://ChenLi2049.github.io/atom.xml><link rel=alternate type=application/json title="Chen Li" href=https://ChenLi2049.github.io/feed.json><link rel="shortcut icon" type=image/png href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII="><style>*,:after,:before{box-sizing:border-box;padding:0}body{font:1rem/1.5 '-apple-system',BlinkMacSystemFont,avenir next,avenir,helvetica,helvetica neue,ubuntu,roboto,noto,segoe ui,arial,sans-serif;text-align:justify;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;padding:2rem;background:rbg(169,169,169,1);color:#000}.skip-link{position:absolute;top:-40px;left:0;background:#eee;z-index:100}.skip-link:focus{top:0}h1,h2,h3,h4,h5{font-size:20px;font-weight:600;text-align:center}strong,b{font-size:inherit;font-weight:600}header{line-height:2;padding-bottom:1.5rem}.link{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.time{font-variant-numeric:tabular-nums;white-space:nowrap}blockquote{border-left:5px solid #eee;padding-left:1rem;margin:0}a:hover,a.heading-link{text-decoration:none}a,a:visited{color:#008b8b}pre{padding:.5rem;overflow:auto;overflow-x:scroll;overflow-wrap:normal}code,pre{font-family:San Francisco Mono,Monaco,consolas,lucida console,dejavu sans mono,bitstream vera sans mono,monospace;font-size:normal;font-size:small;background:#eee}code{margin:.1rem;border:none}ul{list-style-type:circle}ul,ol{padding-left:1.2rem}.list{line-height:2;list-style-type:none;padding-left:0}.list li{padding-bottom:.1rem}.meta{color:#777}.content{max-width:70ch;margin:0 auto}header{line-height:1;display:flex;justify-content:space-between;padding-bottom:1rem}header a{text-decoration:none}header ul{list-style-type:none;padding:0}header li,header a{display:inline}h2.post{padding-top:.5rem}header ul a:first-child{padding-left:1rem}.nav{height:1px;background:#000;content:'';max-width:10%}.list li{display:flex;align-items:baseline}.list li time{flex:initial}.hr-list{margin-top:0;margin-bottom:0;margin-right:.5rem;margin-left:.5rem;height:1px;border:0;border-bottom:1px dotted #ccc;flex:1 0 1rem}.m,hr{border:0;margin:3rem 0}img{max-width:100%;height:auto}.post-date{margin:5% 0}.index-date{color:#9a9a9a}.animate-blink{animation:opacity 1s infinite;opacity:1}@keyframes opacity{0%{opacity:1}50%{opacity:.5}100%{opacity:0}}.tags{display:flex;justify-content:space-between}.tags ul{padding:0;margin:0}.tags li{display:inline}.avatar{height:135px;width:135px;position:relative;margin:0 0 0 10px;float:right;border-radius:25%}table{border-collapse:collapse}table th,table td{border:1px solid #bebebe;padding:0 5px}.toc{margin:0 auto;width:100%;padding:0;margin-bottom:10px;background-color:#f9f9f9}</style><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"posts","name":"Machine Learning Notes: GraphNeT","headline":"Machine Learning Notes: GraphNeT","alternativeHeadline":"","description":"Technically this is only part of the entire blog post. My .ipynb are available at GitHub repository blog-graphnet, see §3.\n§1 Graph \u0026amp; Matrix Graphs can be represented by adjacency matrix, which can be normalized into Frobenius normal form, see Matrices and graphs - by Tivadar Danka - The Palindrome.\nOften, large part of the matrix is empty, which is called Sparse matrix.\n§2 GNN See A Gentle Introduction to Graph Neural Networks - Distill.","inLanguage":"en-us","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/ChenLi2049.github.io\/posts\/20230910-machine-learning-notes-graphnet\/"},"author":{"@type":"Person","name":"Chen Li"},"creator":{"@type":"Person","name":"Chen Li"},"accountablePerson":{"@type":"Person","name":"Chen Li"},"copyrightHolder":"Chen Li","copyrightYear":"2023","dateCreated":"2023-09-10T00:00:00.00Z","datePublished":"2023-09-10T00:00:00.00Z","dateModified":"2023-09-10T00:00:00.00Z","publisher":{"@type":"Organization","name":"Chen Li","url":"https://ChenLi2049.github.io","logo":{"@type":"ImageObject","url":"https:\/\/ChenLi2049.github.io\/assets\/favicon.ico","width":"32","height":"32"}},"image":"https://ChenLi2049.github.io/assets/favicon.ico","url":"https:\/\/ChenLi2049.github.io\/posts\/20230910-machine-learning-notes-graphnet\/","wordCount":"636","genre":["Programming"],"keywords":["Programming"]}</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.6/katex.min.css><script defer src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.6/katex.min.js></script>
<script defer src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.6/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script></head><body><a class=skip-link href=#main>Skip to main</a><main id=main><div class=content><header><p style=padding:0;margin:0><a href=/><b>Chen Li</b>
<span class="text-stone-500 animate-blink"></span></a></p><ul style=padding:0;margin:0><li><a href=/cv/><span>CV</span></a><li><a href=/posts/><span>Posts</span></a><li><a href=/about/><span>About</span></a></li></ul></header><hr class=hr-list style=padding:0;margin:0><section><h2 class=post>Machine Learning Notes: GraphNeT</h2><div class=toc><nav id=TableOfContents><ul><li><a href=#1-graph--matrix>§1 Graph & Matrix</a></li><li><a href=#2-gnn>§2 GNN</a></li><li><a href=#3-graphnet>§3 <code>GraphNeT</code></a><ul><li><a href=#31-shape-of-the-data>§3.1 Shape of the Data</a></li><li><a href=#32-convnet>§3.2 <code>ConvNet</code></a></li><li><a href=#33-dynedge>§3.3 <code>DynEdge</code></a></li><li><a href=#34-model--standardmodel>§3.4 <code>Model</code> & <code>StandardModel</code></a></li></ul></li></ul></nav></div><p>Technically this is only part of the entire blog post. My <code>.ipynb</code> are available at GitHub repository <a href=https://github.com/ChenLi2049/blog-graphnet>blog-graphnet</a>, see §3.</p><h2 id=1-graph--matrix>§1 Graph & Matrix</h2><p>Graphs can be represented by adjacency matrix, which can be normalized into <a href=https://en.wikipedia.org/wiki/Frobenius_normal_form>Frobenius normal form</a>, see <a href=https://thepalindrome.org/p/matrices-and-graphs><em>Matrices and graphs</em> - by Tivadar Danka - The Palindrome</a>.</p><p><img src=https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F485ec4b4-6869-43bb-b17c-e2151a428dbe_1920x1080.png alt loading=lazy decoding=async class=full-width></p><p>Often, large part of the matrix is empty, which is called <a href=https://en.wikipedia.org/wiki/Sparse_matrix>Sparse matrix</a>.</p><h2 id=2-gnn>§2 GNN</h2><p>See <a href=https://distill.pub/2021/gnn-intro/><em>A Gentle Introduction to Graph Neural Networks</em> - Distill.pub</a>.</p><p>After GNN, part of the nodes are highlighted and the number of features of each nodes can be different. This is in consistence with CNN, where parts of the picture is highlighted and the number of channels (RGB $\rightarrow$ many more) can be different (see <a href=https://poloclub.github.io/cnn-explainer/>CNN Explainer</a>).</p><p>For <a href=https://arxiv.org/abs/1710.10903>Graph Attention Networks (GAT)</a>, see <a href=https://nn.labml.ai/graphs/gat/index.html>Graph Attention Networks (GAT) (labml.ai)</a> and <a href=https://nn.labml.ai/graphs/gatv2/index.html>Graph Attention Networks v2 (GATv2) (labml.ai)</a>.</p><h2 id=3-graphnet>§3 <code>GraphNeT</code></h2><p>This section is about GitHub repository <a href=https://github.com/graphnet-team/graphnet><code>GraphNeT</code></a>.</p><p>See their <a href=https://github.com/graphnet-team/graphnet/blob/main/GETTING_STARTED.md>getting started document</a>, especially <a href=https://github.com/graphnet-team/graphnet/blob/main/GETTING_STARTED.md#example-energy-reconstruction-using-modelconfig>the example</a>. In the following article I will focus on the model rather than how to load the data or how to train the model with <code>pytorch-lightning</code>, and I will test these models with dummies. Because I just understand things better in this way and I haven&rsquo;t used these models in practice.</p><p>And my notes are in GitHub repository <a href=https://github.com/ChenLi2049/blog-graphnet>blog-graphnet</a>. <em>In order to be actually used, the models in §3.2 and §3.3 need to be followed by a Fully Connected Layer.</em></p><h3 id=31-shape-of-the-data>§3.1 Shape of the Data</h3><p>See <a href=https://github.com/graphnet-team/graphnet/blob/main/GETTING_STARTED.md#4-the-dataset-and-dataloader-classes>4. The <code>Dataset</code> and <code>DataLoader</code> classes</a> of the getting started document:</p><blockquote><ul><li><code>graph.x</code>: Node feature matrix with shape <code>[num_nodes, num_features]</code></li><li><code>graph.edge_index</code>: Graph connectivity in <a href=https://pytorch.org/docs/stable/sparse.html#sparse-coo-docs>COO format</a> with shape <code>[2, num_edges]</code> and type <code>torch.long</code> (by default this will be <code>None</code>, i.e., the nodes will all be disconnected).</li></ul></blockquote><h3 id=32-convnet>§3.2 <code>ConvNet</code></h3><p><a href=https://github.com/graphnet-team/graphnet/blob/main/src/graphnet/models/gnn/convnet.py><code>graphnet.models.gnn.ConvNet</code></a> is based on <a href=https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.TAGConv.html><code>torch_geometric.nn.TAGConv</code></a>. For the structure of the model, see Fig.3 of <a href=https://arxiv.org/abs/2107.12187>[2107.12187] <em>Reconstruction of Neutrino Events in IceCube using Graph Neural Networks</em></a>.</p><p>In line 46:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>conv1</span> <span style=color:#f92672>=</span> <span style=color:#111>TAGConv</span><span style=color:#111>(</span><span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>nb_inputs</span><span style=color:#111>,</span> <span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>nb_intermediate</span><span style=color:#111>,</span> <span style=color:#ae81ff>2</span><span style=color:#111>)</span>
</span></span></code></pre></div><p>This means that Number of hops $K=2$. When $K=1$, GNN only considers the information of directly adjacent nodes. When $K=2$, GNN takes into account the information of first-order and second-order adjacent nodes. When $K=3$, GNN considers the information of first-order, second-order, and third-order adjacent nodes, and so on. Of course, after few <code>TAGConv</code> layers, the output can gather the information of more than second-order adjacent of the original graph.</p><p>In [2107.12187], it&rsquo;s stated that:</p><blockquote><p>In the simplest way, each pulse can be described by following quantities: the hit DOM, and therefore the position of the pulse, collected charge, and time recorded. &mldr; We can then represent each event by a graph, with the nodes representing the pulses in an abstract 5-dimensional (or 12-dimensional for the Upgrade) space.</p></blockquote><p>Therefore, the event is an input matrix in the shape of <code>[number_of_pulses, 5]</code>, where <code>5</code> is x, y, z, time, charge.</p><h3 id=33-dynedge>§3.3 <code>DynEdge</code></h3><h4 id=331-dynedgeconv>§3.3.1 <code>DynEdgeConv</code></h4><p>The basic layer of <code>DynEdge</code> is <a href=https://github.com/graphnet-team/graphnet/blob/main/src/graphnet/models/components/layers.py><code>graphnet.models.components.layers.DynEdgeConv</code></a>, which is based on <a href=https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.EdgeConv.html><code>torch_geometric.nn.EdgeConv</code></a>.</p><h4 id=332-dynedge>§3.3.2 <code>DynEdge</code></h4><p><a href=https://github.com/graphnet-team/graphnet/blob/main/src/graphnet/models/gnn/dynedge.py><code>graphnet.models.gnn.DynEdge</code></a></p><h4 id=333-dynedgejinst>§3.3.3 <code>DynEdgeJINST</code></h4><p><a href=https://github.com/graphnet-team/graphnet/blob/main/src/graphnet/models/gnn/dynedge_jinst.py><code>graphnet.models.gnn.DynEdgeJINST</code></a> is the model in Fig.2 of <a href=https://arxiv.org/abs/2209.03042>[2209.03042] <em>Graph Neural Networks for Low-Energy Event Classification & Reconstruction in IceCube</em></a>. <code>[n, 6]</code> in the figure means the number of nodes is <code>n</code> and the number of features is <code>6</code>, while <code>[1, n_outputs]</code> means the prediction of this event has <code>n_outputs</code> features (azimuth, zenith, energy, etc.)</p><h4 id=334-dynedgetito>§3.3.4 <code>DynEdgeTITO</code></h4><p><a href=https://github.com/graphnet-team/graphnet/blob/main/src/graphnet/models/gnn/dynedge_kaggle_tito.py><code>graphnet.models.gnn.DynEdgeTITO</code></a> is from <a href=https://www.kaggle.com/competitions/icecube-neutrinos-in-deep-ice/discussion/402976>1st Place Solution | Kaggle</a>.</p><p>An modification for <a href=https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.EdgeConv.html><code>torch_geometric.nn.EdgeConv</code></a> is $$x_i^{\prime} = \sum_{j \in \mathcal{N}(i)} h_{\mathbf{\Theta}}(x_i , x_j - x_i)$$ to $$x_i^{\prime} = \sum_{j \in \mathcal{N}(i)} h_{\mathbf{\Theta}}(x_i , x_j - x_i , x_j)$$</p><p>And this solution also uses custom VMF Loss (not in <a href=https://github.com/graphnet-team/graphnet/blob/main/src/graphnet/models/gnn/dynedge_kaggle_tito.py><code>graphnet.models.gnn.DynEdgeTITO</code></a> of course): $$\text{VMF}=- \kappa \cos{\theta}+C(\kappa)$$ to $$\text{VMF}= - \theta - \kappa \cos{\theta}+C(\kappa)$$, where $\theta$ is the angle between truth and prediction, $\kappa$ is the length of the 3D prediction.</p><h3 id=34-model--standardmodel>§3.4 <code>Model</code> & <code>StandardModel</code></h3><p><a href=https://github.com/graphnet-team/graphnet/blob/main/src/graphnet/models/model.py><code>graphnet.models.Model</code></a> and <a href=https://github.com/graphnet-team/graphnet/blob/main/src/graphnet/models/standard_model.py><code>graphnet.models.StandardModel</code></a> are <a href=https://en.wikipedia.org/wiki/Wrapper_function>wrappers</a> choosing models and goals.</p><div class=post-date><span class="g time">September 10, 2023</span> &#8729;
<a href=https://ChenLi2049.github.io/tags/programming/>programming</a></div></section><div id=comments><script src=https://utteranc.es/client.js repo=ChenLi2049/ChenLi2049.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></div></div></main></body></html>